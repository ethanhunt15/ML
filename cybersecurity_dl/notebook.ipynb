{"cells":[{"source":"![cyber_photo](cyber_photo.jpg)\n\nCyber threats are a growing concern for organizations worldwide. These threats take many forms, including malware, phishing, and denial-of-service (DOS) attacks, compromising sensitive information and disrupting operations. The increasing sophistication and frequency of these attacks make it imperative for organizations to adopt advanced security measures. Traditional threat detection methods often fall short due to their inability to adapt to new and evolving threats. This is where deep learning models come into play.\n\nDeep learning models can analyze vast amounts of data and identify patterns that may not be immediately obvious to human analysts. By leveraging these models, organizations can proactively detect and mitigate cyber threats, safeguarding their sensitive information and ensuring operational continuity.\n\nAs a cybersecurity analyst, you identify and mitigate these threats. In this project, you will design and implement a deep learning model to detect cyber threats. The BETH dataset simulates real-world logs, providing a rich source of information for training and testing your model. The data has already undergone preprocessing, and we have a target label, `sus_label`, indicating whether an event is malicious (1) or benign (0).\n\nBy successfully developing this model, you will contribute to enhancing cybersecurity measures and protecting organizations from potentially devastating cyber attacks.","metadata":{},"id":"d547b11f-1ed0-4d71-9b39-514ba85079ec","cell_type":"markdown"},{"source":"\n### The Data\n\n| Column     | Description              |\n|------------|--------------------------|\n|`processId`|The unique identifier for the process that generated the event - int64 |\n|`threadId`|ID for the thread spawning the log - int64|\n|`parentProcessId`|Label for the process spawning this log - int64|\n|`userId`|ID of user spawning the log|Numerical - int64|\n|`mountNamespace`|Mounting restrictions the process log works within - int64|\n|`argsNum`|Number of arguments passed to the event - int64|\n|`returnValue`|Value returned from the event log (usually 0) - int64|\n|`sus_label`|Binary label as suspicous event (1 is suspicious, 0 is not) - int64|\n\nMore information on the dataset: [BETH dataset](accreditation.md)","metadata":{},"id":"d2967110-9515-4a1b-8ab6-f7bfd5c84d83","cell_type":"markdown"},{"source":"# Make sure to run this cell to use torchmetrics. If you cannot use pip install to install the torchmetrics, you can use sklearn.\n!pip install torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":3001,"lastExecutedAt":1725083252717,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Make sure to run this cell to use torchmetrics. If you cannot use pip install to install the torchmetrics, you can use sklearn.\n!pip install torchmetrics","outputsMetadata":{"0":{"height":437,"type":"stream"}}},"id":"35558034-b7b7-4ab7-8d59-5e6ed281f838","cell_type":"code","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.4.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.6)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"}]},{"source":"# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nimport torchmetrics\nfrom torchmetrics import Accuracy\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score  # uncomment to use sklearn","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1725083252769,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.optim as optim\nimport torchmetrics\nfrom torchmetrics import Accuracy\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score  # uncomment to use sklearn"},"id":"e3121b05-9873-431d-812c-62bceffbf1b3","cell_type":"code","execution_count":41,"outputs":[]},{"source":"# Load preprocessed data\ntrain_df = pd.read_csv('labelled_train.csv')\ntest_df = pd.read_csv('labelled_test.csv')\nval_df = pd.read_csv('labelled_validation.csv')\n\n# View the first 5 rows of training set\ntrain_df.head()","metadata":{"executionCancelledAt":null,"executionTime":359,"lastExecutedAt":1725083253128,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load preprocessed data\ntrain_df = pd.read_csv('labelled_train.csv')\ntest_df = pd.read_csv('labelled_test.csv')\nval_df = pd.read_csv('labelled_validation.csv')\n\n# View the first 5 rows of training set\ntrain_df.head()","outputsMetadata":{"0":{"height":231,"type":"dataFrame"}}},"id":"08bfe2bf-3132-490e-9c16-9026f82b8d73","cell_type":"code","execution_count":42,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"processId","type":"integer"},{"name":"threadId","type":"integer"},{"name":"parentProcessId","type":"integer"},{"name":"userId","type":"integer"},{"name":"mountNamespace","type":"integer"},{"name":"argsNum","type":"integer"},{"name":"returnValue","type":"integer"},{"name":"sus_label","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"processId":[381,381,381,7347,7347],"threadId":[7337,7337,7337,7347,7347],"parentProcessId":[1,1,1,7341,7341],"userId":[100,100,100,0,0],"mountNamespace":[4026532231,4026532231,4026532231,4026531840,4026531840],"argsNum":[5,1,0,2,4],"returnValue":[0,0,0,-2,0],"sus_label":[1,1,1,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"   processId  threadId  parentProcessId  ...  argsNum  returnValue  sus_label\n0        381      7337                1  ...        5            0          1\n1        381      7337                1  ...        1            0          1\n2        381      7337                1  ...        0            0          1\n3       7347      7347             7341  ...        2           -2          1\n4       7347      7347             7341  ...        4            0          1\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processId</th>\n      <th>threadId</th>\n      <th>parentProcessId</th>\n      <th>userId</th>\n      <th>mountNamespace</th>\n      <th>argsNum</th>\n      <th>returnValue</th>\n      <th>sus_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>381</td>\n      <td>7337</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7347</td>\n      <td>7347</td>\n      <td>7341</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7347</td>\n      <td>7347</td>\n      <td>7341</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":42}]},{"source":"# Start coding here\n# Use as many cells as you need\ntest_df.head()","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1725083253181,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here\n# Use as many cells as you need\ntest_df.head()","outputsMetadata":{"0":{"height":231,"type":"dataFrame"}}},"id":"a8b264e9-bbf0-40ec-9b21-6c167220bb61","cell_type":"code","execution_count":43,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"processId","type":"integer"},{"name":"threadId","type":"integer"},{"name":"parentProcessId","type":"integer"},{"name":"userId","type":"integer"},{"name":"mountNamespace","type":"integer"},{"name":"argsNum","type":"integer"},{"name":"returnValue","type":"integer"},{"name":"sus_label","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"processId":[382,379,1,1,1],"threadId":[382,379,1,1,1],"parentProcessId":[1,1,0,0,0],"userId":[101,100,0,0,0],"mountNamespace":[4026532232,4026532231,4026531840,4026531840,4026531840],"argsNum":[3,3,4,4,2],"returnValue":[15,15,0,17,0],"sus_label":[0,0,0,0,0]}},"total_rows":5,"truncation_type":null},"text/plain":"   processId  threadId  parentProcessId  ...  argsNum  returnValue  sus_label\n0        382       382                1  ...        3           15          0\n1        379       379                1  ...        3           15          0\n2          1         1                0  ...        4            0          0\n3          1         1                0  ...        4           17          0\n4          1         1                0  ...        2            0          0\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processId</th>\n      <th>threadId</th>\n      <th>parentProcessId</th>\n      <th>userId</th>\n      <th>mountNamespace</th>\n      <th>argsNum</th>\n      <th>returnValue</th>\n      <th>sus_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>382</td>\n      <td>382</td>\n      <td>1</td>\n      <td>101</td>\n      <td>4026532232</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>379</td>\n      <td>379</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>17</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":43}]},{"source":"val_df.head()","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1725083253241,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"val_df.head()","outputsMetadata":{"0":{"height":231,"type":"dataFrame"}}},"cell_type":"code","id":"9d26ac78-787a-4cb3-981d-23c56d8bff3d","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"processId","type":"integer"},{"name":"threadId","type":"integer"},{"name":"parentProcessId","type":"integer"},{"name":"userId","type":"integer"},{"name":"mountNamespace","type":"integer"},{"name":"argsNum","type":"integer"},{"name":"returnValue","type":"integer"},{"name":"sus_label","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"processId":[381,378,1,1,1],"threadId":[381,378,1,1,1],"parentProcessId":[1,1,0,0,0],"userId":[101,100,0,0,0],"mountNamespace":[4026532232,4026532231,4026531840,4026531840,4026531840],"argsNum":[3,3,4,4,2],"returnValue":[15,15,0,12,0],"sus_label":[0,0,0,0,0]}},"total_rows":5,"truncation_type":null},"text/plain":"   processId  threadId  parentProcessId  ...  argsNum  returnValue  sus_label\n0        381       381                1  ...        3           15          0\n1        378       378                1  ...        3           15          0\n2          1         1                0  ...        4            0          0\n3          1         1                0  ...        4           12          0\n4          1         1                0  ...        2            0          0\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processId</th>\n      <th>threadId</th>\n      <th>parentProcessId</th>\n      <th>userId</th>\n      <th>mountNamespace</th>\n      <th>argsNum</th>\n      <th>returnValue</th>\n      <th>sus_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>381</td>\n      <td>381</td>\n      <td>1</td>\n      <td>101</td>\n      <td>4026532232</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>378</td>\n      <td>378</td>\n      <td>1</td>\n      <td>100</td>\n      <td>4026532231</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>4</td>\n      <td>12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4026531840</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":44}],"execution_count":44},{"source":"1. Loading and Scaling Data","metadata":{},"cell_type":"markdown","id":"d62186de-0c37-4b04-a3f6-9a57b5cb2007"},{"source":"#  separate features and labels, scale the features, and convert data to PyTorch tensors.\n# Drop the sus_label column from each DataFrame to separate features and assign the sus_label column to the labels.\nX_train = train_df.drop('sus_label', axis=1)\ny_train = train_df['sus_label']\nX_test = test_df.drop('sus_label', axis=1)\ny_test = test_df['sus_label']\nX_val = val_df.drop('sus_label', axis=1)\ny_val = val_df['sus_label']","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1725083253301,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#  separate features and labels, scale the features, and convert data to PyTorch tensors.\n# Drop the sus_label column from each DataFrame to separate features and assign the sus_label column to the labels.\nX_train = train_df.drop('sus_label', axis=1)\ny_train = train_df['sus_label']\nX_test = test_df.drop('sus_label', axis=1)\ny_test = test_df['sus_label']\nX_val = val_df.drop('sus_label', axis=1)\ny_val = val_df['sus_label']"},"cell_type":"code","id":"ebde503f-349e-4f13-8d5e-2f97b4c3f8b3","outputs":[],"execution_count":45},{"source":"# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Use the fitted scaler to transform the test and validation data\nX_test_scaled = scaler.transform(X_test)\nX_val_scaled = scaler.transform(X_val)","metadata":{"executionCancelledAt":null,"executionTime":58,"lastExecutedAt":1725083253359,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Use the fitted scaler to transform the test and validation data\nX_test_scaled = scaler.transform(X_test)\nX_val_scaled = scaler.transform(X_val)"},"cell_type":"code","id":"c132701e-c945-4e1d-8ca0-af26bf29e493","outputs":[],"execution_count":46},{"source":"# Convert scaled features and labels to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\nX_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n\n# Print results\nprint(\"Train Features Tensor:\")\nprint(X_train_tensor)\nprint(\"\\nTrain Labels Tensor:\")\nprint(y_train_tensor)\n\nprint(\"\\nTest Features Tensor:\")\nprint(X_test_tensor)\nprint(\"\\nTest Labels Tensor:\")\nprint(y_test_tensor)\n\nprint(\"\\nValidation Features Tensor:\")\nprint(X_val_tensor)\nprint(\"\\nValidation Labels Tensor:\")\nprint(y_val_tensor)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1725083253409,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert scaled features and labels to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\nX_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n\n# Print results\nprint(\"Train Features Tensor:\")\nprint(X_train_tensor)\nprint(\"\\nTrain Labels Tensor:\")\nprint(y_train_tensor)\n\nprint(\"\\nTest Features Tensor:\")\nprint(X_test_tensor)\nprint(\"\\nTest Labels Tensor:\")\nprint(y_test_tensor)\n\nprint(\"\\nValidation Features Tensor:\")\nprint(X_val_tensor)\nprint(\"\\nValidation Labels Tensor:\")\nprint(y_val_tensor)","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"362d6605-eab1-465b-801f-02884f73d5e5","outputs":[{"output_type":"stream","name":"stdout","text":"Train Features Tensor:\ntensor([[-3.3013,  0.2668, -0.8491,  ...,  1.7840,  1.7361, -0.0550],\n        [-3.3013,  0.2668, -0.8491,  ...,  1.7840, -1.2470, -0.0550],\n        [-3.3013,  0.2668, -0.8491,  ...,  1.7840, -1.9927, -0.0550],\n        ...,\n        [ 0.2356,  0.2342,  2.3587,  ..., -0.5871, -1.9927, -0.0550],\n        [ 0.2362,  0.2348, -0.8491,  ..., -0.5871, -1.9927, -0.0550],\n        [ 0.1505,  0.1485, -0.8491,  ..., -0.5871, -1.2470, -0.0550]])\n\nTrain Labels Tensor:\ntensor([1, 1, 1,  ..., 0, 0, 0])\n\nTest Features Tensor:\ntensor([[-3.3008, -3.3237, -0.8491,  ...,  1.7901,  0.2446, -0.0079],\n        [-3.3023, -3.3253, -0.8491,  ...,  1.7840,  0.2446, -0.0079],\n        [-3.4963, -3.5204, -0.8495,  ..., -0.5871,  0.9903, -0.0550],\n        ...,\n        [ 0.3798,  0.3793,  2.5573,  ..., -0.5871,  0.2446, -0.4128],\n        [ 0.3798,  0.3793,  2.5573,  ..., -0.5871,  0.2446, -0.4128],\n        [ 0.3798,  0.3793,  2.5573,  ..., -0.5871,  0.2446, -0.4128]])\n\nTest Labels Tensor:\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\nValidation Features Tensor:\ntensor([[-3.3013, -3.3242, -0.8491,  ...,  1.7901,  0.2446, -0.0079],\n        [-3.3028, -3.3258, -0.8491,  ...,  1.7840,  0.2446, -0.0079],\n        [-3.4963, -3.5204, -0.8495,  ..., -0.5871,  0.9903, -0.0550],\n        ...,\n        [-3.4963, -3.5204, -0.8495,  ..., -0.5871,  0.9903, -0.0550],\n        [-3.4963, -3.5204, -0.8495,  ..., -0.5871,  0.9903,  0.0674],\n        [-3.4963, -3.5204, -0.8495,  ..., -0.5871, -0.5012, -0.0550]])\n\nValidation Labels Tensor:\ntensor([0, 0, 0,  ..., 0, 0, 0])\n"}],"execution_count":47},{"source":"# Create DataLoaders\nbatch_size = 32\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1725083253457,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create DataLoaders\nbatch_size = 32\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)"},"cell_type":"code","id":"a149b799-8429-4247-ad34-90170cd7f6ab","outputs":[],"execution_count":48},{"source":"2. Define the Neural Network Model","metadata":{},"cell_type":"markdown","id":"8c0721b1-7433-4138-bf42-8a265e42d626"},{"source":"import torch\nimport torch.nn as nn\n\n# Define the number of features in the dataset\nnum_features = X_train_tensor.shape[1]\n\n# Define the neural network using nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(num_features, 128),  # Input layer\n    nn.ReLU(),\n    nn.Linear(128, 64),           # Hidden layer\n    nn.ReLU(),\n    nn.Linear(64, 2)              # Output layer: 2 units for binary classification\n)\n","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1725083253505,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch\nimport torch.nn as nn\n\n# Define the number of features in the dataset\nnum_features = X_train_tensor.shape[1]\n\n# Define the neural network using nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(num_features, 128),  # Input layer\n    nn.ReLU(),\n    nn.Linear(128, 64),           # Hidden layer\n    nn.ReLU(),\n    nn.Linear(64, 2)              # Output layer: 2 units for binary classification\n)\n","outputsMetadata":{"0":{"height":374,"type":"stream"}}},"cell_type":"code","id":"f687bbf9-c170-48fc-8beb-e3f04252001d","outputs":[],"execution_count":49},{"source":"Train The Model","metadata":{},"cell_type":"markdown","id":"60f71f7e-4cb3-42c8-9962-730ca854b6fc"},{"source":"# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize the optimizer\noptimizer = optim.SGD(\n    model.parameters(),\n    lr=1e-3,\n    weight_decay=1e-4\n)\n\n# Number of epochs\nnum_epochs = 20\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n\n    running_loss = 0.0\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()  # Clear the gradients\n\n        outputs = model(batch_X)  # Forward pass\n\n        loss = criterion(outputs, batch_y)  # Compute the loss\n\n        loss.backward()  # Backward pass to compute gradients\n\n        optimizer.step()  # Update the model parameters\n\n        running_loss += loss.item() * batch_X.size(0)\n\n    # Average loss for the epoch\n    epoch_loss = running_loss / len(train_loader.dataset)\n\n    # Print epoch loss\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n\nprint(\"Training complete.\")\n","metadata":{"executionCancelledAt":null,"executionTime":1423455,"lastExecutedAt":1725084676961,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize the optimizer\noptimizer = optim.SGD(\n    model.parameters(),\n    lr=1e-3,\n    weight_decay=1e-4\n)\n\n# Number of epochs\nnum_epochs = 20\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n\n    running_loss = 0.0\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()  # Clear the gradients\n\n        outputs = model(batch_X)  # Forward pass\n\n        loss = criterion(outputs, batch_y)  # Compute the loss\n\n        loss.backward()  # Backward pass to compute gradients\n\n        optimizer.step()  # Update the model parameters\n\n        running_loss += loss.item() * batch_X.size(0)\n\n    # Average loss for the epoch\n    epoch_loss = running_loss / len(train_loader.dataset)\n\n    # Print epoch loss\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n\nprint(\"Training complete.\")\n","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"cell_type":"code","id":"052e1abb-27f9-428f-b74d-fef087b5c060","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [1/20], Loss: 0.0273\nEpoch [2/20], Loss: 0.0038\nEpoch [3/20], Loss: 0.0034\nEpoch [4/20], Loss: 0.0032\nEpoch [5/20], Loss: 0.0031\nEpoch [6/20], Loss: 0.0030\nEpoch [7/20], Loss: 0.0029\nEpoch [8/20], Loss: 0.0029\nEpoch [9/20], Loss: 0.0028\nEpoch [10/20], Loss: 0.0028\nEpoch [11/20], Loss: 0.0027\nEpoch [12/20], Loss: 0.0027\nEpoch [13/20], Loss: 0.0026\nEpoch [14/20], Loss: 0.0026\nEpoch [15/20], Loss: 0.0026\nEpoch [16/20], Loss: 0.0026\nEpoch [17/20], Loss: 0.0025\nEpoch [18/20], Loss: 0.0025\nEpoch [19/20], Loss: 0.0025\nEpoch [20/20], Loss: 0.0025\nTraining complete.\n"}],"execution_count":50},{"source":"4. Evaluating the Model","metadata":{},"cell_type":"markdown","id":"db9bb1a2-2e22-42b0-8d68-aa8aa305a71d"},{"source":"# Initialize the accuracy metric\naccuracy_metric = torchmetrics.Accuracy(num_classes=2, task='binary')\n\n# Function to evaluate the model\ndef evaluate_model(loader):\n    model.eval()  # Set the model to evaluation mode\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch_X, batch_y in loader:\n            outputs = model(batch_X)\n            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n\n            correct += (predicted == batch_y).sum().item()\n            total += batch_y.size(0)\n\n    accuracy = correct / total\n    return accuracy\n\n# Evaluate on training, testing, and validation datasets\ntrain_accuracy = evaluate_model(train_loader)\ntest_accuracy = evaluate_model(test_loader)\nval_accuracy = evaluate_model(val_loader)\n\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")\nprint(f\"Testing Accuracy: {test_accuracy:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":51976,"lastExecutedAt":1725084728937,"lastExecutedByKernel":"94521608-3c73-4c82-b51a-c6578027e726","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize the accuracy metric\naccuracy_metric = torchmetrics.Accuracy(num_classes=2, task='binary')\n\n# Function to evaluate the model\ndef evaluate_model(loader):\n    model.eval()  # Set the model to evaluation mode\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch_X, batch_y in loader:\n            outputs = model(batch_X)\n            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n\n            correct += (predicted == batch_y).sum().item()\n            total += batch_y.size(0)\n\n    accuracy = correct / total\n    return accuracy\n\n# Evaluate on training, testing, and validation datasets\ntrain_accuracy = evaluate_model(train_loader)\ntest_accuracy = evaluate_model(test_loader)\nval_accuracy = evaluate_model(val_loader)\n\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")\nprint(f\"Testing Accuracy: {test_accuracy:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"14364d67-c8ac-4244-80f5-55f13a19c208","outputs":[{"output_type":"stream","name":"stdout","text":"Training Accuracy: 0.9996\nTesting Accuracy: 0.9276\nValidation Accuracy: 1.0000\n"}],"execution_count":51}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}