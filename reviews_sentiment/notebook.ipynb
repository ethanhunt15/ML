{"cells":[{"source":"![image](car.jpeg)\n\n**Car-ing is sharing**, an auto dealership company for car sales and rental, is taking their services to the next level thanks to **Large Language Models (LLMs)**.\n\nAs their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n\nThe solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a carâ€™s text review, answering a customer question, summarizing or translating text, etc.\n","metadata":{},"id":"9aabafca-8129-4943-b865-d5e897637253","cell_type":"markdown"},{"source":"## Before you start\n\nIn order to complete the project you may wish to install some Hugging Face libraries such as `transformers` and `evaluate`.","metadata":{},"id":"972c0004-e8c7-4539-967d-0c32167ae540","cell_type":"markdown"},{"source":"!pip install transformers\n!pip install evaluate\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","metadata":{"executionCancelledAt":null,"executionTime":6365,"lastExecutedAt":1725124104253,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install transformers\n!pip install evaluate\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)","outputsMetadata":{"0":{"height":553,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545"},"id":"5325a4c0-ceb3-4b66-acd2-5eadcefe3a63","cell_type":"code","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.23.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.8.17)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: evaluate in /home/repl/.local/lib/python3.8/site-packages (0.4.2)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.10.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.23.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.5.1)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.0)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.13)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2022.7.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (23.2)\nRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (7.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (0.10.15)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2019.11.28)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.14.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n"}]},{"source":"1. Classify car reviews \n\nLoad a sentiment analysis LLM to classify the sentiment of each review in the dataset into POSITIVE or NEGATIVE, and utilize the real labels to calculate the accuracy and F1 score of predictions.\n","metadata":{},"cell_type":"markdown","id":"88d67ed0-8f4d-4a42-a77e-562f00f31d96"},{"source":"from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForQuestionAnswering, AutoModelForSeq2SeqLM\nfrom datasets import load_metric\nfrom nltk.translate.bleu_score import corpus_bleu\nimport csv","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1725124104305,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForQuestionAnswering, AutoModelForSeq2SeqLM\nfrom datasets import load_metric\nfrom nltk.translate.bleu_score import corpus_bleu\nimport csv"},"cell_type":"code","id":"7c47e696-68ed-4ad6-80f0-70c39087895d","outputs":[],"execution_count":15},{"source":"# Initialize sentiment analysis model\n#sentiment_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n#sentiment_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n#sentiment_analyzer = pipeline('sentiment-analysis', model=sentiment_model, tokenizer=sentiment_tokenizer)\n\n# Initialize sentiment analysis model and tokenizer\nsentiment_model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nsentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)\nsentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\nsentiment_analyzer = pipeline('sentiment-analysis', model=sentiment_model, tokenizer=sentiment_tokenizer)\n","metadata":{"executionCancelledAt":null,"executionTime":1812,"lastExecutedAt":1725124106117,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize sentiment analysis model\n#sentiment_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n#sentiment_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n#sentiment_analyzer = pipeline('sentiment-analysis', model=sentiment_model, tokenizer=sentiment_tokenizer)\n\n# Initialize sentiment analysis model and tokenizer\nsentiment_model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nsentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)\nsentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\nsentiment_analyzer = pipeline('sentiment-analysis', model=sentiment_model, tokenizer=sentiment_tokenizer)\n","outputsMetadata":{"0":{"height":80,"type":"stream"},"4":{"height":80,"type":"stream"}}},"cell_type":"code","id":"2a62bf1b-cc33-43aa-b3ff-a0091754ca6f","outputs":[],"execution_count":16},{"source":"# Initialize translation model\ntranslation_model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-es')\ntranslation_tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es')\ntranslator = pipeline('translation_en_to_es', model=translation_model, tokenizer=translation_tokenizer)","metadata":{"executionCancelledAt":null,"executionTime":3881,"lastExecutedAt":1725124110000,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize translation model\ntranslation_model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-es')\ntranslation_tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es')\ntranslator = pipeline('translation_en_to_es', model=translation_model, tokenizer=translation_tokenizer)"},"cell_type":"code","id":"7d1407ab-3ef2-4d3c-a312-c00b8d8b5c0e","outputs":[],"execution_count":17},{"source":"# Initialize extractive QA model\nqa_model = AutoModelForQuestionAnswering.from_pretrained('deepset/minilm-uncased-squad2')\nqa_tokenizer = AutoTokenizer.from_pretrained('deepset/minilm-uncased-squad2')\nqa_pipeline = pipeline('question-answering', model=qa_model, tokenizer=qa_tokenizer)\n\n# Initialize summarization model\nsummarizer = pipeline('summarization')","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":101,"type":"stream"},"4":{"height":80,"type":"stream"},"5":{"height":101,"type":"stream"},"17":{"height":80,"type":"stream"}}},"cell_type":"code","id":"5bfbac23-7f51-43ec-ad9d-50b1de62d4e6","outputs":[{"output_type":"stream","name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n"},{"ename":"Error","evalue":"Failed to execute this cell, please try again.","output_type":"error","traceback":[]}],"execution_count":5},{"source":"import pandas as pd\n# Read the car reviews\n#with open('./data/car_reviews.csv', 'r') as file:\n#    reader = csv.reader(file)\n#    reviews = list(reader)\n\n# Extract reviews\n#review_1 = reviews[0][0]\n#review_2 = reviews[1][0]\n#review_5 = reviews[4][0]\n# Load car reviews dataset\ndata_path = './data/car_reviews.csv'\ndf = pd.read_csv(data_path, delimiter=';', header=0)\n\n# Extract reviews\nreviews = df['Review'].tolist()\nclasses = df['Class'].tolist()\nprint (reviews)\nprint (classes)","metadata":{"executionCancelledAt":1725124121391,"executionTime":774,"lastExecutedAt":1725124077051,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n# Read the car reviews\n#with open('./data/car_reviews.csv', 'r') as file:\n#    reader = csv.reader(file)\n#    reviews = list(reader)\n\n# Extract reviews\n#review_1 = reviews[0][0]\n#review_2 = reviews[1][0]\n#review_5 = reviews[4][0]\n# Load car reviews dataset\ndata_path = './data/car_reviews.csv'\ndf = pd.read_csv(data_path, delimiter=';', header=0)\n\n# Extract reviews\nreviews = df['Review'].tolist()\nclasses = df['Class'].tolist()\nprint (reviews)\nprint (classes)","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"cell_type":"code","id":"91e8c6a3-804a-4b86-8ed1-d1e410a9e89b","outputs":[{"output_type":"stream","name":"stdout","text":"['I am very satisfied with my 2014 Nissan NV SL. I use this van for my business deliveries and personal use. Camping, road trips, etc. We dont have any children so I store most of the seats in my warehouse. I wanted the passenger van for the rear air conditioning. We drove our van from Florida to California for a Cross Country trip in 2014. We averaged about 18 mpg. We drove thru a lot of rain and It was a very comfortable and stable vehicle. The V8 Nissan Titan engine is a 500k mile engine. It has been tested many times by delivery and trucking companies. This is why Nissan gives you a 5 year or 100k mile bumper to bumper warranty. Many people are scared about driving this van because of its size. But with front and rear sonar sensors, large mirrors and the back up camera. It is easy to drive. The front and rear sensors also monitor the front and rear sides of the bumpers making it easier to park close to objects. Our Nissan NV is a Tow Monster. It pulls our 5000 pound travel trailer like its not even there. I have plenty of power to pass a vehicle if needed. The 5.6 liter engine produces 317 hp. I have owned Chevy and Ford vans and there were not very comfortable and had little cockpit room. The Nissan NV is the only vehicle made that has the engine forward like a pick up truck giving the driver plenty of room and comfort in the cockpit area. I dont have any negatives to say about my NV. This is a wide vehicle. The only modification I would like to see from Nissan is for them to add amber side mirror marker lights.BTW. I now own a 2016 Nissan NVP SL. Love it.', \"The car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the interior is well-built. The transmission failed a few years ago, and the dealer replaced it under warranty with no issues. Now, about 60k miles later, the transmission is failing again. It sounds like a truck, and the issues are well-documented. The dealer tells me it is normal, refusing to do anything to resolve the issue. After owning the car for 4 years, there are many other vehicles I would purchase over this one. Initially, I really liked what the brand is about: ride quality, reliability, etc. But I will not purchase another one. Despite these concerns, I must say, the level of comfort in the car has always been satisfactory, but not worth the rest of issues found.\", 'My first foreign car. Love it, I would buy another.', 'I\\'ve come across numerous reviews praising the Rogue, and I genuinely feel like I might be missing something. It\\'s only been a week since I got the car, and I am genuinely disappointed. I truly wish I could return it. My main concern revolves around what I see as a significant design flaw (which I believe also exists in the Murano, though that wasn\\'t much better and considerably pricier). The rear windshield is just too small. The headrests in the back seat obstruct the sides of the rearview window. This \"Crossover\" feels more like a cheaply made compact car. My other vehicle is a Sonata, and it provides a significantly quieter and smoother ride. I did not anticipate this car to ride so roughly; my 2006 Pathfinder had a smoother ride! I would rate this car a 5 all around.', \"I've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\"]\n['POSITIVE', 'NEGATIVE', 'POSITIVE', 'NEGATIVE', 'POSITIVE']\n"}],"execution_count":6},{"source":"# Sentiment Analysis\ndef get_sentiments(reviews):\n    results = sentiment_analyzer(reviews)\n    labels = [result['label'] for result in results]\n    return labels\n\nsentiments = get_sentiments([review[0] for review in reviews])\npredicted_labels = sentiments\npredictions = [1 if label == \"POSITIVE\" else 0 for label in predicted_labels]","metadata":{"executionCancelledAt":1725124121392,"executionTime":263,"lastExecutedAt":1725124077314,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Sentiment Analysis\ndef get_sentiments(reviews):\n    results = sentiment_analyzer(reviews)\n    labels = [result['label'] for result in results]\n    return labels\n\nsentiments = get_sentiments([review[0] for review in reviews])\npredicted_labels = sentiments\npredictions = [1 if label == \"POSITIVE\" else 0 for label in predicted_labels]"},"cell_type":"code","id":"2ca49473-c887-43d6-844e-cc164ef37e64","outputs":[],"execution_count":7},{"source":"# Load real labels (assuming they are in the same order as reviews)\n#with open('real_labels.csv', 'r') as file:\n#    reader = csv.reader(file)\n#    real_labels = list(reader)\nreal_labels = [1 if label[0] == \"POSITIVE\" else 0 for label in classes]\n","metadata":{"executionCancelledAt":1725124121394,"executionTime":45,"lastExecutedAt":1725124077361,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load real labels (assuming they are in the same order as reviews)\n#with open('real_labels.csv', 'r') as file:\n#    reader = csv.reader(file)\n#    real_labels = list(reader)\nreal_labels = [1 if label[0] == \"POSITIVE\" else 0 for label in classes]\n"},"cell_type":"code","id":"c50ed4d8-e423-48eb-b257-6750d66a4612","outputs":[],"execution_count":8},{"source":"# Calculate metrics\naccuracy_metric = load_metric('accuracy')\nf1_metric = load_metric('f1')\n\naccuracy_result = accuracy_metric.compute(predictions=predictions, references=real_labels)['accuracy']\nf1_result = f1_metric.compute(predictions=predictions, references=real_labels)['f1']","metadata":{"executionCancelledAt":1725124121395,"executionTime":411,"lastExecutedAt":1725124077772,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Calculate metrics\naccuracy_metric = load_metric('accuracy')\nf1_metric = load_metric('f1')\n\naccuracy_result = accuracy_metric.compute(predictions=predictions, references=real_labels)['accuracy']\nf1_result = f1_metric.compute(predictions=predictions, references=real_labels)['f1']"},"cell_type":"code","id":"f017dfb9-2175-48ea-994b-d4d5039c1df0","outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0785704c2cb5497c96ea5011f04045f8"},"application/json":{"n":0,"total":1652,"elapsed":0.0066568851470947266,"ncols":null,"nrows":null,"prefix":"Downloading builder script","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbebc7be5343494594dfc5c1265d1c42"},"application/json":{"n":0,"total":2318,"elapsed":0.0069239139556884766,"ncols":null,"nrows":null,"prefix":"Downloading builder script","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1000,"initial":0,"colour":null}},"metadata":{}}],"execution_count":9},{"source":"# Translation\nfirst_review = reviews[0]\nsentences_to_translate = ' '.join(first_review.split('.')[:2])\n\ntranslated = translator(sentences_to_translate, max_length=30)[0]['translation_text']\ntranslated_review = translated","metadata":{"executionCancelledAt":1725124121396,"executionTime":2840,"lastExecutedAt":1725124080612,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Translation\nfirst_review = reviews[0]\nsentences_to_translate = ' '.join(first_review.split('.')[:2])\n\ntranslated = translator(sentences_to_translate, max_length=30)[0]['translation_text']\ntranslated_review = translated","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"2a69ffe8-0d9a-4f17-979f-44c91d0f8aa7","outputs":[],"execution_count":10},{"source":"# BLEU score calculation\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import corpus_bleu\n\n# Read reference translations for BLEU score\nwith open('./data/reference_translations.txt', 'r') as file:\n    references = [line.strip().split('\\t') for line in file]\n\n# Ensure the references are formatted correctly\nformatted_references = []\nformatted_references.append([ref.strip() for ref in references[0] if ref.strip()])\n\n# Calculate BLEU score\n# Convert translated_review to list of hypotheses\nhypotheses = [translated_review]\n\n# Ensure the number of hypotheses matches the number of references\nif len(hypotheses) == len(formatted_references):\n    bleu_score = corpus_bleu(formatted_references, hypotheses)\nelse:\n    bleu_score = None\n    print(\"Mismatch in the number of references and hypotheses. BLEU score cannot be computed.\")\n","metadata":{"executionCancelledAt":1725124121397,"executionTime":88,"lastExecutedAt":1725124080702,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# BLEU score calculation\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import corpus_bleu\n\n# Read reference translations for BLEU score\nwith open('./data/reference_translations.txt', 'r') as file:\n    references = [line.strip().split('\\t') for line in file]\n\n# Ensure the references are formatted correctly\nformatted_references = []\nformatted_references.append([ref.strip() for ref in references[0] if ref.strip()])\n\n# Calculate BLEU score\n# Convert translated_review to list of hypotheses\nhypotheses = [translated_review]\n\n# Ensure the number of hypotheses matches the number of references\nif len(hypotheses) == len(formatted_references):\n    bleu_score = corpus_bleu(formatted_references, hypotheses)\nelse:\n    bleu_score = None\n    print(\"Mismatch in the number of references and hypotheses. BLEU score cannot be computed.\")\n","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"8a62a38a-69bd-4194-b2be-ad3873346591","outputs":[],"execution_count":11},{"source":"# Extractive QA\nquestion = \"What did he like about the brand?\"\ncontext = reviews[1]\nqa_result = qa_pipeline(question=question, context=context)\nanswer = qa_result['answer']\n\n# Summarization\nlast_review = reviews[4]\nsummarized_result = summarizer(last_review, max_length=55, min_length=50, do_sample=False)\nsummarized_text = summarized_result[0]['summary_text']\n\n# Print results\nprint(\"Sentiment Analysis:\")\nprint(\"Predicted Labels:\", predicted_labels)\nprint(\"Predictions:\", predictions)\nprint(\"Accuracy:\", accuracy_result)\nprint(\"F1 Score:\", f1_result)\n\nprint(\"\\nTranslation:\")\nprint(\"Translated Review:\", translated_review)\nprint(\"BLEU Score:\", bleu_score)\n\nprint(\"\\nExtractive QA Answer:\")\nprint(\"Answer:\", answer)\n\nprint(\"\\nSummarization:\")\nprint(\"Summarized Text:\", summarized_text)","metadata":{"executionCancelledAt":1725124121398,"executionTime":15504,"lastExecutedAt":1725124096206,"lastExecutedByKernel":"2c34505d-3721-4743-8890-f611767df545","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extractive QA\nquestion = \"What did he like about the brand?\"\ncontext = reviews[1]\nqa_result = qa_pipeline(question=question, context=context)\nanswer = qa_result['answer']\n\n# Summarization\nlast_review = reviews[4]\nsummarized_result = summarizer(last_review, max_length=55, min_length=50, do_sample=False)\nsummarized_text = summarized_result[0]['summary_text']\n\n# Print results\nprint(\"Sentiment Analysis:\")\nprint(\"Predicted Labels:\", predicted_labels)\nprint(\"Predictions:\", predictions)\nprint(\"Accuracy:\", accuracy_result)\nprint(\"F1 Score:\", f1_result)\n\nprint(\"\\nTranslation:\")\nprint(\"Translated Review:\", translated_review)\nprint(\"BLEU Score:\", bleu_score)\n\nprint(\"\\nExtractive QA Answer:\")\nprint(\"Answer:\", answer)\n\nprint(\"\\nSummarization:\")\nprint(\"Summarized Text:\", summarized_text)","outputsMetadata":{"0":{"height":416,"type":"stream"}}},"cell_type":"code","id":"b03c10f8-f7ed-4382-a5be-c1c5fc18e988","outputs":[{"output_type":"stream","name":"stdout","text":"Sentiment Analysis:\nPredicted Labels: ['POSITIVE', 'NEGATIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE']\nPredictions: [1, 0, 1, 1, 1]\nAccuracy: 0.2\nF1 Score: 0.0\n\nTranslation:\nTranslated Review: Estoy muy satisfecho con mi Nissan NV SL 2014 Uso esta camioneta para mis entregas de negocios y uso personal\nBLEU Score: 0.8237388624214945\n\nExtractive QA Answer:\nAnswer: ride quality, reliability\n\nSummarization:\nSummarized Text:  Nissan Rogue provides the desired SUV experience without burdening me with an exorbitant payment . Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more . The engine delivers strong performance, and\n"}],"execution_count":12},{"source":"The 'distilbert-base-uncased-finetuned-sst-2-english' model is a good choice of pre-trained LLM for binary sentiment classification","metadata":{},"cell_type":"markdown","id":"e4592f1b-7b6c-4a5d-b00f-1f4cd480fd40"},{"source":"Label mapping for metrics computation\nIn a text classification context, the accuracy and F1 score metrics in the evaluate library take two arguments: references, containing the ground truth labels, and predictions, containing the classification outputs produced by your model.\nBefore passing these two collections of labels to the metric for computation, it is necessary to map the categorical POSITIVE, NEGATIVE labels in the outputs and dataset ground-truth into numerical {0,1} labels.\nHere is an example illustrating how to do it for the ground-truth labels: references = [1 if label == \"POSITIVE\" else 0 for label in real_labels]","metadata":{},"cell_type":"markdown","id":"0bec2cff-9319-461b-b491-d16dbaf10e43"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}